#!/usr/bin/env python3
"""
Channel.io TTS Integration for Vapi
ì±„ë„í†¡ì˜ ê³ í’ˆì§ˆ í•œêµ­ì–´ TTS APIë¥¼ Vapiì™€ í†µí•©
"""

import os
import io
import logging
import requests
import struct
import subprocess
from typing import Optional, Iterator

logger = logging.getLogger(__name__)

# Channel.io TTS API ì„¤ì •
CHANNELTTS_API_BASE = "https://ch-tts-streaming-demo.channel.io"
CHANNELTTS_VOICE_ID = "hana"  # ê³ ì • voice ID
DEFAULT_LATENCY_LEVEL = 3  # 0-4, 3 = ë¹ ë¥¸ ì‘ë‹µ (ê¶Œì¥)


def generate_speech_stream(
    text: str,
    latency_level: int = DEFAULT_LATENCY_LEVEL,
    output_format: str = "pcm_24000"
) -> Iterator[bytes]:
    """
    Channel.io TTS APIë¡œ ìŒì„± ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
    
    Args:
        text: í•œêµ­ì–´ í…ìŠ¤íŠ¸
        latency_level: ì§€ì—°ì‹œê°„ ìµœì í™” ìˆ˜ì¤€ (0-4, 3 ê¶Œì¥)
        output_format: ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸: pcm_24000)
    
    Yields:
        ì˜¤ë””ì˜¤ ì²­í¬ (bytes)
    
    Raises:
        requests.RequestException: API í˜¸ì¶œ ì‹¤íŒ¨
    """
    url = f"{CHANNELTTS_API_BASE}/v1/text-to-speech/{CHANNELTTS_VOICE_ID}/stream"
    
    params = {
        "optimize_streaming_latency": latency_level
    }
    
    payload = {
        "text": text,
        "model_id": "default",
        "voice_settings": {},
        "output_format": output_format
    }
    
    headers = {
        "Content-Type": "application/json",
        "Accept": "audio/pcm"  # PCM í˜•ì‹ ìš”ì²­
    }
    
    try:
        logger.info(f"[ChannelTTS] Generating speech for: {text[:50]}...")
        
        with requests.post(
            url,
            params=params,
            json=payload,
            headers=headers,
            stream=True,
            timeout=30
        ) as response:
            response.raise_for_status()
            
            chunk_count = 0
            for chunk in response.iter_content(chunk_size=4096):
                if chunk:
                    chunk_count += 1
                    if chunk_count == 1:
                        logger.info("[ChannelTTS] First chunk received!")
                    yield chunk
            
            logger.info(f"[ChannelTTS] Streaming complete ({chunk_count} chunks)")
    
    except requests.RequestException as e:
        logger.error(f"[ChannelTTS] API request failed: {e}")
        raise


def generate_speech(
    text: str,
    latency_level: int = DEFAULT_LATENCY_LEVEL,
    output_format: str = "pcm_24000"
) -> bytes:
    """
    Channel.io TTS APIë¡œ ìŒì„± ìƒì„± (ì „ì²´ ë°”ì´ë„ˆë¦¬ ë°˜í™˜)
    
    Args:
        text: í•œêµ­ì–´ í…ìŠ¤íŠ¸
        latency_level: ì§€ì—°ì‹œê°„ ìµœì í™” ìˆ˜ì¤€ (0-4, 3 ê¶Œì¥)
        output_format: ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸: pcm_24000)
    
    Returns:
        PCM ì˜¤ë””ì˜¤ ë°ì´í„° (bytes)
    
    Raises:
        requests.RequestException: API í˜¸ì¶œ ì‹¤íŒ¨
    """
    url = f"{CHANNELTTS_API_BASE}/v1/text-to-speech/{CHANNELTTS_VOICE_ID}/stream"
    
    params = {
        "optimize_streaming_latency": latency_level
    }
    
    payload = {
        "text": text,
        "model_id": "default",
        "voice_settings": {},
        "output_format": output_format
    }
    
    headers = {
        "Content-Type": "application/json"
    }
    
    try:
        logger.info(f"[ChannelTTS] Generating speech for: {text[:50]}...")
        
        # stream=Falseë¡œ í•œ ë²ˆì— ë°›ê¸°
        response = requests.post(
            url,
            params=params,
            json=payload,
            headers=headers,
            timeout=30
        )
        response.raise_for_status()
        
        audio_data = response.content
        logger.info(f"[ChannelTTS] Generated {len(audio_data)} bytes of audio")
        
        return audio_data
    
    except requests.RequestException as e:
        logger.error(f"[ChannelTTS] API request failed: {e}")
        raise


def linear_to_mulaw(sample: int) -> int:
    """
    16-bit linear PCM â†’ Î¼-law ë³€í™˜ (ë‹¨ì¼ ìƒ˜í”Œ)
    í‘œì¤€ G.711 Î¼-law ì•Œê³ ë¦¬ì¦˜ (ITU-T G.711)
    """
    BIAS = 0x84  # 132
    CLIP = 32635
    
    # Get sign
    sign = 0x80 if sample < 0 else 0x00
    
    # Get magnitude
    if sample < 0:
        sample = -sample
    
    if sample > CLIP:
        sample = CLIP
    
    sample = sample + BIAS
    
    # Find exponent
    exponent = 7
    for exp_lut in [0x4000, 0x2000, 0x1000, 0x800, 0x400, 0x200, 0x100, 0x80]:
        if sample >= exp_lut:
            break
        exponent -= 1
    
    # Get mantissa
    mantissa = (sample >> (exponent + 3)) & 0x0F
    
    # Combine and invert
    mulaw_byte = ~(sign | (exponent << 4) | mantissa)
    
    return mulaw_byte & 0xFF


def resample_pcm(pcm_data: bytes, from_rate: int, to_rate: int) -> bytes:
    """
    Simple PCM resampling (nearest neighbor)
    """
    import array
    
    # Convert bytes to int16 array
    samples = array.array('h', pcm_data)  # 'h' = signed short (16-bit)
    
    # Calculate resampling ratio
    ratio = from_rate / to_rate
    output_length = int(len(samples) / ratio)
    
    # Resample
    resampled = array.array('h')
    for i in range(output_length):
        src_index = int(i * ratio)
        if src_index < len(samples):
            resampled.append(samples[src_index])
    
    return resampled.tobytes()


def convert_pcm_to_mulaw(pcm_data: bytes, sample_rate: int = 24000) -> bytes:
    """
    PCM ì˜¤ë””ì˜¤ë¥¼ Î¼-law (G.711) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    VapiëŠ” ì „í™” í†µí™”ì— Î¼-lawë¥¼ ì‚¬ìš©
    
    Pure Python êµ¬í˜„ (Python 3.13+ í˜¸í™˜, audioop ë¶ˆí•„ìš”):
    - PCM s16le (16-bit signed little-endian) â†’ Î¼-law
    - 24kHz â†’ 8kHz ë¦¬ìƒ˜í”Œë§ (ì „í™” í†µí™” í‘œì¤€)
    
    Args:
        pcm_data: PCM ì˜¤ë””ì˜¤ ë°ì´í„° (16-bit, mono)
        sample_rate: ì…ë ¥ ìƒ˜í”Œë ˆì´íŠ¸ (ê¸°ë³¸: 24000)
    
    Returns:
        Î¼-law ì˜¤ë””ì˜¤ ë°ì´í„° (bytes, 8kHz, mono)
    """
    try:
        import array
        
        # 1. Resample: 24kHz â†’ 8kHz (ì „í™” í†µí™” í‘œì¤€)
        if sample_rate != 8000:
            resampled_data = resample_pcm(pcm_data, sample_rate, 8000)
            logger.info(f"[ChannelTTS] Resampled: {len(pcm_data)} â†’ {len(resampled_data)} bytes ({sample_rate}Hz â†’ 8kHz)")
        else:
            resampled_data = pcm_data
        
        # 2. PCM (16-bit) â†’ Î¼-law
        samples = array.array('h', resampled_data)  # 'h' = signed short
        mulaw_bytes = bytearray()
        
        for sample in samples:
            mulaw_bytes.append(linear_to_mulaw(sample))
        
        mulaw_data = bytes(mulaw_bytes)
        
        logger.info(f"[ChannelTTS] PCM â†’ Î¼-law: {len(pcm_data)} â†’ {len(mulaw_data)} bytes")
        
        return mulaw_data
    
    except Exception as e:
        logger.error(f"[ChannelTTS] PCM â†’ Î¼-law conversion failed: {e}")
        raise


def generate_speech_for_vapi(text: str, latency_level: int = DEFAULT_LATENCY_LEVEL) -> bytes:
    """
    Vapi í†µí™”ìš© ìŒì„± ìƒì„± (PCM â†’ Î¼-law ë³€í™˜ í¬í•¨)
    
    Args:
        text: í•œêµ­ì–´ í…ìŠ¤íŠ¸
        latency_level: ì§€ì—°ì‹œê°„ ìµœì í™” ìˆ˜ì¤€ (0-4, 3 ê¶Œì¥)
    
    Returns:
        Î¼-law ì˜¤ë””ì˜¤ ë°ì´í„° (Vapi í†µí™”ìš©)
    
    Raises:
        Exception: ìŒì„± ìƒì„± ë˜ëŠ” ë³€í™˜ ì‹¤íŒ¨
    """
    # 1. Channel.io TTSë¡œ PCM ìƒì„±
    pcm_data = generate_speech(text, latency_level, output_format="pcm_24000")
    
    # 2. PCM â†’ Î¼-law ë³€í™˜
    mulaw_data = convert_pcm_to_mulaw(pcm_data, sample_rate=24000)
    
    logger.info(f"[ChannelTTS] Vapi-ready audio: {len(mulaw_data)} bytes (Î¼-law)")
    
    return mulaw_data


def test_tts(text: str = "ì•ˆë…•í•˜ì„¸ìš”! í´ë¦¬ë‚˜ì˜ˆìš” ğŸŒ¸"):
    """
    TTS ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    
    Args:
        text: í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ (ê¸°ë³¸: í´ë¦¬ë‚˜ ì¸ì‚¬)
    """
    import time
    
    print(f"Testing Channel.io TTS with text: {text}")
    
    # 1. ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
    print("\n[1] Streaming test...")
    start_time = time.time()
    
    chunks = []
    first_chunk_time = None
    
    for chunk in generate_speech_stream(text):
        if first_chunk_time is None:
            first_chunk_time = time.time() - start_time
            print(f"âœ… First chunk received in {first_chunk_time:.3f}s")
        
        chunks.append(chunk)
    
    total_time = time.time() - start_time
    total_bytes = sum(len(c) for c in chunks)
    
    print(f"âœ… Streaming complete: {total_bytes} bytes in {total_time:.3f}s")
    print(f"   First chunk latency: {first_chunk_time:.3f}s")
    print(f"   Total chunks: {len(chunks)}")
    
    # 2. ì „ì²´ ë°”ì´ë„ˆë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸
    print("\n[2] Full binary test...")
    start_time = time.time()
    
    audio_data = generate_speech(text)
    
    total_time = time.time() - start_time
    print(f"âœ… Generated {len(audio_data)} bytes in {total_time:.3f}s")
    
    # 3. Vapiìš© ë³€í™˜ í…ŒìŠ¤íŠ¸
    print("\n[3] Vapi Î¼-law conversion test...")
    start_time = time.time()
    
    mulaw_data = generate_speech_for_vapi(text)
    
    total_time = time.time() - start_time
    print(f"âœ… Vapi-ready audio: {len(mulaw_data)} bytes in {total_time:.3f}s")
    
    # 4. íŒŒì¼ ì €ì¥ (ì„ íƒ)
    output_dir = os.path.expanduser("~/.openclaw/skills/vapi/test_output")
    os.makedirs(output_dir, exist_ok=True)
    
    # PCM ì €ì¥
    pcm_path = os.path.join(output_dir, "test_pcm.raw")
    with open(pcm_path, "wb") as f:
        f.write(audio_data)
    print(f"\nğŸ“ PCM audio saved: {pcm_path}")
    
    # Î¼-law ì €ì¥
    mulaw_path = os.path.join(output_dir, "test_mulaw.raw")
    with open(mulaw_path, "wb") as f:
        f.write(mulaw_data)
    print(f"ğŸ“ Î¼-law audio saved: {mulaw_path}")
    
    print("\nâœ… All tests passed!")
    print("\nTo play PCM audio:")
    print(f"  ffplay -f s16le -ar 24000 -ac 1 {pcm_path}")
    print("\nTo play Î¼-law audio:")
    print(f"  ffplay -f mulaw -ar 8000 -ac 1 {mulaw_path}")


if __name__ == "__main__":
    import sys
    
    # CLI ì¸í„°í˜ì´ìŠ¤
    if len(sys.argv) > 1:
        text = " ".join(sys.argv[1:])
        test_tts(text)
    else:
        test_tts()
